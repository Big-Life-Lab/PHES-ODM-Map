---
toc: true
toc-depth: 2
css: assets/styles.css
---

```{r, echo=FALSE, eval=TRUE, file="../R/doc_mdtables.R"}
```

# Mapping Configuration Files

Mapping configuration files are YAML files that specify all the configuration options for mapping from one database format to another.

The main root component of the configuration file is the `tables` key, consisting of an array of dictionaries specifying how to construct each of the output (mapped) tables.

Below is an example configuration file:

```{yaml, file="../assets/examples/mapping_configs/odm2_long_to_wide.yaml"}
```

# meta

The `meta` root section provides informational details for the configuration file, such as a title, author, relevant web links, etc.

```yaml
meta:
    title: ODM 2.0 Long to Wide
    version: 0.0.1
    author: Martin Wellman
    contact: mwellman@ohri.ca
    links: https://phes-odm.org
    last_modified: 2023-12-18
```

# tables

The main root element in the configuration file is the `tables` key. It is an array of dictionaries, where each dictionary specifies how to construct (or map to) one output table. The `tables` dictionary includes the output table name (`output_table`), the inputs used to construct the output table (`main_inputs` and `other_inputs`), and the mapping operations performed in the construction (`operations` and `post_operations`). These dictionary elements are described below.

## output_table

This is the name of the output table for the mapping. It is a string.

## main_inputs

```yaml
main_inputs:
    input_table: measures
    group_by: [ date, sampleID ]
```

![Figure 1: Example construction of output table based on input table](assets/odm_example_table_construction.png){fig-align="center"}

`main_inputs` is the main input table for the current output table. We will iterate over the rows of this table one at a time. For each input row, we will apply all mapping operations one at a time to generate the new row(s) for the output table. When proceeding to each subsequent mapping operation, we carry forward the resulting output rows from the previous operation. This will construct the new row(s) iteratively, growing the row(s) as we proceed. Once all operations have been applied, we save the output rows and proceed to the next input row and repeat the process to generate other new rows.

We can also group the rows of the main input by certain columns, such as by `date` and/or `sampleID`. By default (if no grouping is specified), each input row is considered its own group (ie. a group of size one). For a group, when iterating over the mapping operations, we pass all the rows of the group to the current mapping operation.

The above example will use the `measures` table as the main input and group the rows by both `date` and `sampleID`. We take the first group, pass it to all mapping operations and save the resulting output. We then proceed to the next group and repeat the process.

An optional `input_name` key can be used to give the input table a different name, so that we reference it by that different name later on in the config file. For example, below we would reference the main input table as `myMeasures` throughout the configuration file, rather than as `measures`:

```yaml
main_inputs:
    input_table: measures
    input_name: myMeasures
    group_by: [ date, sampleID ]
```

## other_inputs

```yaml
other_inputs:
    -   input_table: samples
        match: 
            input_column: [ date, sampleID ]
            match_table: measures
            match_column: [ date, sampleID ]
    -   input_table: contacts
        match:
            input_column: contactID
            match_table: measures
            match_column: contactID
```

`other_inputs` specifies all the other tables that act as inputs to the mapping operations, but they are not iterated over as with the main input table. It can be a string (a single table), or an array of strings or dictionaries. For dictionary elements we can specify filtering operations to select only specific rows from the table. For example if the main input table has a field named `contactID` that's a foreign key into the `contacts` table, we might want to select the row in the `contacts` table for that `contactID`. At each mapping operation we would pass that row into the operation, giving the operation access to additional information about the contact (eg. their first name, last name, and email address). We would typically want this filtering to result in a single row selected from the `contacts` table. This filtering is specified by the `match` key. 

In the example below we are selecting row(s) from the `contacts` table, by finding matches in the `contactID` column (specified by `input_column`). The value we select for is the value in the `contactID` column of the `measures` table (specified by `match_column` and `match_table`, respectively):

```yaml
-   input_table: contacts
    match:
        input_column: contactID
        match_table: measures
        match_column: contactID
```

One optional attribute of an `other_inputs` dictionary is the `input_name` key. This can help avoid name conflicts where the table name can possibly reference more than one input table. For example if the `samples` table appears in two different `other_inputs`, where in one input we filter based on `date` and in another input we filter based on `sampleID`, as below:

```yaml
other_inputs:
    -   input_table: samples
        input_name: samples_date
        match: 
            input_column: date
            match_table: measures
            match_column: date
    -   input_table: samples
        input_name: samples_sampleID
        match: 
            input_column: sampleID
            match_table: measures
            match_column: sampleID
```

## operations

The operations key specifies all operations to perform on the rows of the inputs to generate the mapped table. There are various types of operations that can be performed, such as pivoting wider, pivoting longer, copying, setting, etc. Each operation is specified by a dictionary, with the operation name specified by the `operation` key and the operation-specific configuration specified by the `operation_config` key. Below is a simple example with two different operations:

```yaml
operations:
    -   operation: pivot_wider
        operation_config:
            target_column_elements: [ compartment, specimen, fraction_analysed, measure, unit, aggregation, index ]
            target_column_separator: _
            target_column_suffix: _value
            source_table: measures
            source_column: value
    -   operation: copy
        operation_config:
            target_column: mr_reportDate
            source_table: measures
            source_column: reportDate
```

A full list of allowable operations is specified in the [Mapping Operations](mapping-operations.html) document.

## post_operations

Once an output table has been fully constructed, by passing all groups to all operations, some additional operations can be performed on the final table. These are called 'post operations'. Only a few operations can be applied as post operations. We specify these operations with the output table's `post_operations` key, whose values are in an identical format as the `operations` key.

Commonly used post operations are the `sort_rows` or `order_columns` operations. These can sort the rows of the table or rearrange the columns, respectively.

# Creating New Output Rows

When starting the mapping we begin with a single empty output row and iteratively construct the output. Many operations (such as `pivot_wider`, `copy`, and `set`) do not create new output rows in addition to the initial single row, even if multiple input rows exist. However, some operations (such as `pivot_longer`) will create more than one output row. Once multiple output rows are created they are carried forward to subsequent operations.

When an operation creates a new row, values in the new rows that the operation does not populate itself are populated with the values from the pre-existing rows. When copying down through the empty rows, we cycle through these pre-existing rows when copying to each subsequent new row.

![Figure 2: Copying down values that are missing in newly added rows](assets/odm_broadcast_missing_values.png)

# Multiple Input and Output Rows

When grouping input rows with the `group_by` key we will have multiple rows acting as input for each operation. In some cases we will also have multiple output rows (eg. if a `pivot_longer` operation is performed). How an operation handles multiple input rows and/or multiple output rows is operation-specific. However, the general recommended guideline is to maintain the relationship that a value in output row i corresponds to input row i mod n (i % n), where n is the number of input rows (using 0-based row indices).

For example, if we have two input rows with a `date` field and 3 output rows, a `copy` operation will copy the first date to the first output row, the second date to the second output row, then cycle back to copying the first date to the third output row.

![Figure 3: Cycling through the input rows when copying values to multiple output rows](assets/odm_multiple_input_and_output_rows.png)

How an operation handles multiple input rows and/or multiple output rows should be documented for each operation. At the moment, there will be multiple input rows only if the `group_by` key is specified for the `main_inputs` table. Grouping is typically done if we want to perform a `pivot_wider` operation.
